{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d46cb141",
   "metadata": {},
   "source": [
    "# <center>ML Final Project</center>\n",
    "\n",
    "## <center>Rocchio Classification</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf210e0",
   "metadata": {},
   "source": [
    "#### For text and document classification, the Rocchio Classification algorithm is a straightforward but powerful technique. It functions by classifying newly created documents according to their vector representations in a high-dimensional space, therefore organizing them into specified groups. Using training data, the algorithm determines the \"center\" of each category's documents, or centroids, for each category. Rocchio measures a new document's distance from these centroids and places it in the category with the closest centroid. The technique aims to maximize the distance from the centroids of other classes while minimizing the distance between a document and the correct class centroid.\n",
    "\n",
    "#### Because of its simplicity and effectiveness, Rocchio is a well-liked option for some jobs, such as sentiment analysis and spam filtering, where it excels. Because of its efficacious handling of high-dimensional data, it remains popular in a wide range of natural language processing applications.\n",
    "\n",
    "\n",
    "\n",
    "#### Research paper URL - \"https://arxiv.org/pdf/1904.08067v5.pdf\"\n",
    "\n",
    "#### Dataset URL - \"https://github.com/kk7nc/Text_Classification/tree/master/Data\"\n",
    "\n",
    "#### Github URL - \"https://github.com/kk7nc/Text_Classification/tree/master/code\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf4bb9c",
   "metadata": {},
   "source": [
    "### Dataset loaded..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a1a6da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=8, micro=8, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "RMDL: Random Multimodel Deep Learning for Classification\n",
    " * Copyright (C) 2018  Kamran Kowsari <kk7nc@virginia.edu>\n",
    " * Last Update: 04/25/2018\n",
    " * This file is part of  RMDL project, University of Virginia.\n",
    " * Free to use, change, share and distribute source code of RMDL\n",
    " * Refrenced paper : RMDL: Random Multimodel Deep Learning for Classification\n",
    " * Refrenced paper : An Improvement of Data Classification using Random Multimodel Deep Learning (RMDL)\n",
    " * Comments and Error: email: kk7nc@virginia.edu\n",
    "'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import os, sys, tarfile\n",
    "import numpy as np\n",
    "import zipfile\n",
    "\n",
    "if sys.version_info >= (3, 0, 0):\n",
    "    import urllib.request as urllib  # ugly but works\n",
    "else:\n",
    "    import urllib\n",
    "\n",
    "print(sys.version_info)\n",
    "\n",
    "# image shape\n",
    "\n",
    "\n",
    "# path to the directory with the data\n",
    "DATA_DIR = '.\\Glove'\n",
    "\n",
    "# url of the binary data\n",
    "\n",
    "\n",
    "\n",
    "# path to the binary train file with image data\n",
    "\n",
    "\n",
    "def download_and_extract(data='Wikipedia'):\n",
    "    \"\"\"\n",
    "    Download and extract the GloVe\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    if data=='Wikipedia':\n",
    "        DATA_URL = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
    "    elif data=='Common_Crawl_840B':\n",
    "        DATA_URL = 'http://nlp.stanford.edu/data/wordvecs/glove.840B.300d.zip'\n",
    "    elif data=='Common_Crawl_42B':\n",
    "        DATA_URL = 'http://nlp.stanford.edu/data/wordvecs/glove.42B.300d.zip'\n",
    "    elif data=='Twitter':\n",
    "        DATA_URL = 'http://nlp.stanford.edu/data/wordvecs/glove.twitter.27B.zip'\n",
    "    else:\n",
    "        print(\"prameter should be Twitter, Common_Crawl_42B, Common_Crawl_840B, or Wikipedia\")\n",
    "        exit(0)\n",
    "\n",
    "\n",
    "    dest_directory = DATA_DIR\n",
    "    if not os.path.exists(dest_directory):\n",
    "        os.makedirs(dest_directory)\n",
    "    filename = DATA_URL.split('/')[-1]\n",
    "    filepath = os.path.join(dest_directory, filename)\n",
    "    print(filepath)\n",
    "\n",
    "    path = os.path.abspath(dest_directory)\n",
    "    if not os.path.exists(filepath):\n",
    "        def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\rDownloading %s %.2f%%' % (filename,\n",
    "                                                          float(count * block_size) / float(total_size) * 100.0))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        filepath, _ = urllib.urlretrieve(DATA_URL, filepath)#, reporthook=_progress)\n",
    "\n",
    "\n",
    "        zip_ref = zipfile.ZipFile(filepath, 'r')\n",
    "        zip_ref.extractall(DATA_DIR)\n",
    "        zip_ref.close()\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2310719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=8, micro=8, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "RMDL: Random Multimodel Deep Learning for Classification\n",
    " * Copyright (C) 2018  Kamran Kowsari <kk7nc@virginia.edu>\n",
    " * Last Update: 04/25/2018\n",
    " * This file is part of  RMDL project, University of Virginia.\n",
    " * Free to use, change, share and distribute source code of RMDL\n",
    " * Refrenced paper : RMDL: Random Multimodel Deep Learning for Classification\n",
    " * Refrenced paper : An Improvement of Data Classification using Random Multimodel Deep Learning (RMDL)\n",
    " * Comments and Error: email: kk7nc@virginia.edu\n",
    "'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import os, sys, tarfile\n",
    "import numpy as np\n",
    "\n",
    "if sys.version_info >= (3, 0, 0):\n",
    "    import urllib.request as urllib  # ugly but works\n",
    "else:\n",
    "    import urllib\n",
    "\n",
    "print(sys.version_info)\n",
    "\n",
    "# image shape\n",
    "\n",
    "\n",
    "# path to the directory with the data\n",
    "DATA_DIR = '.\\data_WOS'\n",
    "\n",
    "# url of the binary data\n",
    "DATA_URL = 'http://kowsari.net/WebOfScience.tar.gz'\n",
    "\n",
    "\n",
    "# path to the binary train file with image data\n",
    "\n",
    "\n",
    "def download_and_extract():\n",
    "    \"\"\"\n",
    "    Download and extract the WOS datasets\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    dest_directory = DATA_DIR\n",
    "    if not os.path.exists(dest_directory):\n",
    "        os.makedirs(dest_directory)\n",
    "    filename = DATA_URL.split('/')[-1]\n",
    "    filepath = os.path.join(dest_directory, filename)\n",
    "\n",
    "\n",
    "    path = os.path.abspath(dest_directory)\n",
    "    if not os.path.exists(filepath):\n",
    "        def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\rDownloading %s %.2f%%' % (filename,\n",
    "                                                          float(count * block_size) / float(total_size) * 100.0))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        filepath, _ = urllib.urlretrieve(DATA_URL, filepath, reporthook=_progress)\n",
    "\n",
    "        print('Downloaded', filename)\n",
    "\n",
    "        tarfile.open(filepath, 'r').extractall(dest_directory)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d7887a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestCentroid\n",
    "# from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "X_train = newsgroups_train.data\n",
    "X_test = newsgroups_test.data\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', NearestCentroid()),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predicted = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9092f538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.49      0.60       319\n",
      "           1       0.44      0.76      0.56       389\n",
      "           2       0.75      0.68      0.71       394\n",
      "           3       0.71      0.59      0.65       392\n",
      "           4       0.81      0.71      0.76       385\n",
      "           5       0.83      0.66      0.74       395\n",
      "           6       0.49      0.88      0.63       390\n",
      "           7       0.86      0.76      0.80       396\n",
      "           8       0.91      0.86      0.89       398\n",
      "           9       0.85      0.79      0.82       397\n",
      "          10       0.95      0.80      0.87       399\n",
      "          11       0.94      0.66      0.78       396\n",
      "          12       0.40      0.70      0.51       393\n",
      "          13       0.84      0.49      0.62       396\n",
      "          14       0.89      0.72      0.80       394\n",
      "          15       0.55      0.73      0.63       398\n",
      "          16       0.68      0.76      0.71       364\n",
      "          17       0.97      0.70      0.81       376\n",
      "          18       0.54      0.53      0.53       310\n",
      "          19       0.58      0.39      0.47       251\n",
      "\n",
      "    accuracy                           0.69      7532\n",
      "   macro avg       0.74      0.68      0.69      7532\n",
      "weighted avg       0.74      0.69      0.70      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f409027",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "#### Using the 20 Newsgroups dataset, the Rocchio Classification algorithm performs moderately well, with an overall accuracy of 69%. The algorithm struggles in some categories, with scores as low as 0.47 and 0.51; nevertheless, it excels in others, obtaining f1-scores as high as 0.89 and 0.87. The findings imply that although Rocchio works well for some classes—especially those with sharp differences—it might not be the greatest option for datasets that have overlapping or less distinct categories. Rocchio has promise overall, but for better results, it might need to be adjusted further or used in a different way."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
